# ğŸ™ï¸ AI Voice Chat - Intelligent Interview Assistant# AI Voice Chat ğŸ™ï¸<<<<<<< HEAD



[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)# AI Voice Chat ğŸ™ï¸# AI Voice Chat ğŸ™ï¸# ğŸ™ï¸ Talkito AI Interview Platform

[![Python 3.13+](https://img.shields.io/badge/python-3.13+-blue.svg)](https://www.python.org/downloads/)

[![React 19](https://img.shields.io/badge/react-19.1.1-blue.svg)](https://reactjs.org/)An AI-powered interview assistant that conducts voice-based technical interviews using Google Gemini AI and ElevenLabs text-to-speech.=======

[![Flask](https://img.shields.io/badge/flask-3.0.0-green.svg)](https://flask.palletsprojects.com/)

# AI Voice chat ğŸ™ï¸# ğŸ™ï¸ Talkito AI Interview Platform

An AI-powered interview assistant that conducts voice-based technical interviews using **Google Gemini AI** for intelligent responses and **ElevenLabs** for natural text-to-speech synthesis. Perfect for practicing technical interviews, conducting remote interviews, or educational purposes.

## âœ¨ Features>>>>>>> 99d687f216995b82e7db2678c93f7ad5efabc3a8

## âœ¨ Key Features



- ğŸ¤ **Voice-to-Voice Interaction** - Natural conversation flow with speech recognition

- ğŸ¤– **AI-Powered Intelligence** - Google Gemini 2.0 Flash for context-aware responses- ğŸ¤ **Voice-to-Voice Interaction** - Speak naturally and get AI responses

- ğŸ—£ï¸ **Premium Voice Synthesis** - ElevenLabs API for human-like speech quality

- ğŸ¯ **Technical Interview Focus** - Specialized for web development interviews- ğŸ¤– **AI-Powered** - Uses Google Gemini 2.0 Flash for intelligent responses  

- ğŸ”„ **Conversation Memory** - Maintains context throughout the interview

- ğŸ¨ **Modern UI** - Clean, responsive React interface with real-time feedback- ğŸ—£ï¸ **Natural Speech** - ElevenLabs API for human-like voice synthesisAn AI-powered interview assistant that conducts voice-based technical interviews using Google Gemini AI and ElevenLabs text-to-speech.

- ğŸ”§ **Flexible Configuration** - Multiple voice models and fallback options

- ğŸ¯ **Technical Interviews** - Designed for web development interviews

## ğŸ¬ Demo

- ğŸ”„ **Conversation Flow** - Maintains context throughout the interview

```

User: "Tell me about your React experience"

AI: "That's great! Can you walk me through how you handle state management in complex React applications? Do you prefer Redux, Context API, or other solutions?"

```## ğŸš€ Quick Setup## âœ¨ FeaturesAn AI-powered interview assistant that conducts voice-based technical interviews using Google Gemini AI and ElevenLabs text-to-speech.An AI-powered interview platform that conducts realistic technical interviews using voice interaction. Built with React, Flask, ElevenLabs TTS, Gemini AI, and FFmpeg.



## ğŸ“Š Project Metrics (COCOMO Analysis)



| Metric | Value |### 1. Clone Repository

|--------|-------|

| **Lines of Code** | 1,770 SLOC (917 current + 853 planned) |```bash

| **Development Effort** | 4.54 person-months |

| **Development Time** | 4.15 months |git clone https://github.com/vandandalvi/AI_voiceChat.git- ğŸ¤ **Voice-to-Voice Interaction** - Speak naturally and get AI responses

| **Team Size** | 1 developer (optimal) |

| **Project Complexity** | Organic mode |cd AI_voiceChat

| **Cost per Line** | $20.52 |

```- ğŸ¤– **AI-Powered** - Uses Google Gemini 2.0 Flash for intelligent responses  

## ğŸš€ Quick Start



### Prerequisites

### 2. Download FFmpeg (Required)- ğŸ—£ï¸ **Natural Speech** - ElevenLabs API for human-like voice synthesis## âœ¨ Features## ğŸŒŸ Features

- **Python 3.13+** - [Download here](https://www.python.org/downloads/)

- **Node.js 18+** - [Download here](https://nodejs.org/)```bash

- **FFmpeg** - Required for audio processing

# Windows: Download FFmpeg essentials build- ğŸ¯ **Technical Interviews** - Designed for web development interviews

### 1. Clone Repository

# ğŸ“¥ Direct download: https://www.gyan.dev/ffmpeg/builds/ffmpeg-release-essentials.zip

```bash

git clone https://github.com/vandandalvi/AI_voiceChat.git# ğŸ“ Extract to project root folder (should create ffmpeg-xxx-essentials_build folder)<<<<<<< HEAD

cd AI_voiceChat

```- ğŸ”„ **Conversation Flow** - Maintains context throughout the interview



### 2. Download FFmpeg (Required)# Alternative: Go to https://www.gyan.dev/ffmpeg/builds/=======



```bash# Choose "essentials" build (NOT full build - smaller download)- ğŸ”„ **Conversation Flow** - Maintains context throughout the interview- **Interactive UI**: Clean, modern React interface

# Windows: Download FFmpeg essentials build

# ğŸ“¥ Direct link: https://www.gyan.dev/ffmpeg/builds/ffmpeg-release-essentials.zip```

# ğŸ“ Extract to project root folder

- **Conversation History**: Track the entirdinterview dialogue

# Alternative: Visit https://www.gyan.dev/ffmpeg/builds/

# Choose "essentials" build (smaller download)### 3. Backend Setup

```

```bash## ğŸš€ Quick Setup

### 3. Backend Setup

cd backend

```bash

cd backendpip install -r requirements.txt## ğŸ—ï¸ Architecture

pip install -r requirements.txt

``````



### 4. Configure API Keys### 1. Clone Repository



```bash### 4. Configure API Keys

# Copy example environment file

copy .env.example .env```bash```bash```



# Edit .env and add your API keys:# Copy example file

GEMINI_API_KEY=your_gemini_api_key_here

ELEVENLABS_API_KEY=your_elevenlabs_api_key_herecopy .env.example .envgit clone https://github.com/vandandalvi/AI_voiceChat.gitUser speaks â†’ FFmpeg Audio Processing â†’ Speech-to-Text â†’ Gemini AI â†’ ElevenLabs TTS â†’ AI speaks

ELEVENLABS_VOICE_ID=nPczCjzI2devNBz1zQrb

ELEVENLABS_MODEL=eleven_flash_v2_5

```

# Edit .env and add your API keys:cd AI_voiceChat```

#### ğŸ”‘ Getting API Keys

GEMINI_API_KEY=your_gemini_api_key_here

**Google Gemini API (Required)**

1. Visit [Google AI Studio](https://makersuite.google.com/app/apikey)ELEVENLABS_API_KEY=your_elevenlabs_api_key_here```

2. Create a new API key

3. Add to `.env` fileELEVENLABS_VOICE_ID=nPczCjzI2devNBz1zQrb



**ElevenLabs API (Required)**```## ğŸ“‹ Prerequisites

1. Sign up at [ElevenLabs](https://elevenlabs.io/)

2. Navigate to Profile â†’ API Keys

3. Create and copy your API key

4. Browse [Voice Library](https://elevenlabs.io/voice-library) for voice IDs### 5. Get API Keys### 2. Backend Setup



### 5. Start Backend Server



```bash**Gemini API (Required):**```bash- Python 3.8+

python app.py

```1. Go to [Google AI Studio](https://makersuite.google.com/app/apikey)

âœ… Backend runs on `http://localhost:5000`

2. Create API key and add to `.env`cd backend- Node.js 16+

### 6. Frontend Setup



```bash

cd frontend/vite-project**ElevenLabs API (Required):**pip install -r requirements.txt- FFmpeg (included in project)

npm install

npm run dev1. Sign up at [ElevenLabs](https://elevenlabs.io/)

```

âœ… Frontend runs on `http://localhost:5173`2. Get API key from Profile â†’ API Keys```- Gemini API Key



### 7. Start Interviewing!3. Browse [Voice Library](https://elevenlabs.io/voice-library) for Voice IDs



1. Open `http://localhost:5173` in your browser- ElevenLabs API Key

2. Click **"Start Interview"** 

3. Wait for AI greeting### 6. Run Backend

4. Click **"Start Speaking"** to respond

5. Have a natural conversation!```bash### 3. Configure API Keys



## ğŸ—ï¸ Architecturepython app.py



```mermaid``````bash## ğŸš€ Setup Instructions

graph LR

    A[User Voice] --> B[MediaRecorder API]Backend runs on `http://localhost:5000`

    B --> C[Flask Backend]

    C --> D[FFmpeg Audio Processing]# Copy example file

    D --> E[Google Speech Recognition]

    E --> F[Gemini AI Processing]### 7. Frontend Setup

    F --> G[ElevenLabs TTS]

    G --> H[Audio Response]```bashcopy .env.example .env### Backend Setup

    H --> I[User Hears AI]

```cd frontend/vite-project>>>>>>> 99d687f216995b82e7db2678c93f7ad5efabc3a8



## ğŸ› ï¸ Technology Stacknpm install



### Backendnpm run dev

- **Flask 3.0.0** - Web framework

- **Google Generative AI** - AI text generation```

- **ElevenLabs API** - Premium text-to-speech

- **SpeechRecognition** - Speech-to-text conversionFrontend runs on `http://localhost:5173`## ğŸš€ Quick Setup- ğŸ¤ **Voice-to-Voice Interaction** - Speak naturally and get AI responses- **Voice-Based Interview**: Natural conversation with AI interviewer

- **gTTS** - Fallback text-to-speech

- **FFmpeg** - Audio processing pipeline



### Frontend## ğŸ¯ Usage

- **React 19.1.1** - UI framework

- **Vite 7.1.7** - Build tool and dev server

- **Modern CSS** - Responsive design with animations

- **MediaRecorder API** - Voice recording1. Open `http://localhost:5173`### 1. Clone Repository- ğŸ¤– **AI-Powered** - Uses Google Gemini 2.0 Flash for intelligent responses  - **Real-time Speech Processing**: Uses FFmpeg for audio processing

- **Fetch API** - Backend communication

2. Click **"Start Interview"** 

### APIs & Services

- **Google Gemini 2.0 Flash** - AI conversation3. Wait for AI greeting```bash

- **ElevenLabs Flash v2.5** - Voice synthesis

- **Google Speech Recognition** - Free STT4. Click **"Start Speaking"** to respond



## âš™ï¸ Configuration5. Click **"Stop Speaking"** when donegit clone https://github.com/vandandalvi/AI_voiceChat.git- ğŸ—£ï¸ **Natural Speech** - ElevenLabs API for human-like voice synthesis- **AI-Powered Responses**: Gemini 2.0 Flash for intelligent conversation



### Voice Models (ElevenLabs)6. Continue the conversation!



```envcd AI_voiceChat

# Choose your preferred model:

ELEVENLABS_MODEL=eleven_flash_v2_5    # Fastest, lowest cost âœ…## ğŸ› ï¸ Tech Stack

ELEVENLABS_MODEL=eleven_turbo_v2_5    # High quality, fast

ELEVENLABS_MODEL=eleven_multilingual_v2  # 44 languages```- ğŸ¯ **Technical Interviews** - Designed for web development interviews- **Natural Voice**: ElevenLabs text-to-speech for human-like voice

```

- **Backend:** Flask, Python 3.13

### Voice Settings (Customizable in app.py)

- **Frontend:** React 19, Vite

```python

"voice_settings": {- **AI:** Google Gemini 2.0 Flash

    "stability": 0.3,           # Lower = more expressive (0.2-0.5)

    "similarity_boost": 0.8,    # Higher = closer to voice character- **TTS:** ElevenLabs Flash v2.5 ### 2. Download FFmpeg (Required)- ğŸ”„ **Conversation Flow** - Maintains context throughout the interview- **Interactive UI**: Clean, modern React interface

    "style": 0.3,               # Style exaggeration (0.0-1.0)

    "use_speaker_boost": True   # Enhanced clarity- **STT:** Google Speech Recognition

}

```- **Audio:** FFmpeg (download required)```bash



### Fallback Configuration



```env## âš™ï¸ Configuration# Windows: Download FFmpeg essentials build- **Conversation History**: Track the entire interview dialogue

# Enable free Google TTS if ElevenLabs fails

USE_GTTS_FALLBACK=false

VOICE_SPEED=1.35

GTTS_TLD=co.uk  # UK accent for professional sound### Voice Settings (in `app.py`)# ğŸ“¥ Direct download: https://www.gyan.dev/ffmpeg/builds/ffmpeg-release-essentials.zip

```

```python

## ğŸ“ Project Structure

"voice_settings": {# ğŸ“ Extract to project root folder (should create ffmpeg-xxx-essentials_build folder)## ğŸš€ Quick Setup

```

AI_voiceChat/    "stability": 0.3,        # Lower = more expressive  

â”œâ”€â”€ ğŸ“‚ backend/

â”‚   â”œâ”€â”€ ğŸ app.py              # Main Flask server (378 lines)    "similarity_boost": 0.8, # Higher = closer to voice

â”‚   â”œâ”€â”€ ğŸ“‹ requirements.txt    # Python dependencies

â”‚   â”œâ”€â”€ ğŸ“„ .env.example        # Environment template    "style": 0.3,            # Style exaggeration

â”‚   â””â”€â”€ ğŸ”’ .env               # Your API keys (git ignored)

â”œâ”€â”€ ğŸ“‚ frontend/vite-project/    "use_speaker_boost": True # Enhanced clarity# Alternative: Go to https://www.gyan.dev/ffmpeg/builds/## ğŸ—ï¸ Architecture

â”‚   â”œâ”€â”€ ğŸ“‚ src/

â”‚   â”‚   â”œâ”€â”€ âš›ï¸ App.jsx         # Main React component (248 lines)}

â”‚   â”‚   â”œâ”€â”€ ğŸ¨ App.css         # Styling (291 lines)

â”‚   â”‚   â””â”€â”€ ğŸ¯ main.jsx        # App entry point```# Choose "essentials" build (NOT full build - smaller download)

â”‚   â””â”€â”€ ğŸ“¦ package.json        # Node dependencies

â”œâ”€â”€ ğŸ“‚ ffmpeg-xxx-essentials_build/  # Download separately

â”œâ”€â”€ ğŸš« .gitignore             # Protected files

â””â”€â”€ ğŸ“– README.md              # This file### ElevenLabs Models (in `.env`)```### 1. Clone Repository

```

- `eleven_flash_v2_5` - Fastest, lowest cost âœ…

## ğŸ”§ API Endpoints

- `eleven_turbo_v2_5` - High quality, fast

| Method | Endpoint | Description |

|--------|----------|-------------|- `eleven_multilingual_v2` - 44 languages

| `POST` | `/api/start-interview` | Initialize interview session |

| `POST` | `/api/process-audio` | Process voice â†’ AI â†’ speech |### 3. Backend Setup```bash```

| `POST` | `/api/text-to-speech` | Convert text to audio |

| `GET` | `/api/conversation-history` | Retrieve conversation |## ğŸ”§ Troubleshooting

| `POST` | `/api/reset` | Reset conversation state |

| `GET` | `/api/health` | Server health check |```bash



## ğŸš¨ Troubleshooting**FFmpeg Not Found:** Download from link above and extract to project root  



### Common Issues**ElevenLabs 401 Error:** Set `USE_GTTS_FALLBACK=true` in `.env`  cd backendgit clone https://github.com/vandandalvi/AI_voiceChat.gitUser speaks â†’ FFmpeg Audio Processing â†’ Speech-to-Text â†’ Gemini AI â†’ ElevenLabs TTS â†’ AI speaks



**âŒ FFmpeg Not Found****No Microphone:** Grant browser permissions  

```bash

# Download from: https://www.gyan.dev/ffmpeg/builds/ffmpeg-release-essentials.zip**CORS Errors:** Ensure Flask-CORS is installed  pip install -r requirements.txt

# Extract to project root folder

```



**âŒ ElevenLabs 401 Error**## ğŸ“ Project Structure```cd AI_voiceChat```

```env

# Set fallback mode in .env:

USE_GTTS_FALLBACK=true

``````



**âŒ Microphone Access Denied**AI_voiceChat/

- Grant browser microphone permissions

- Use HTTPS in productionâ”œâ”€â”€ backend/### 4. Configure API Keys```

- Try Chrome/Edge browsers

â”‚   â”œâ”€â”€ app.py              # Main Flask server

**âŒ CORS Errors**

```bashâ”‚   â”œâ”€â”€ requirements.txt    # Dependencies```bash

pip install flask-cors  # Should be in requirements.txt

```â”‚   â”œâ”€â”€ .env.example        # API keys template



### Performance Tipsâ”‚   â””â”€â”€ .env                # Your API keys (git ignored)# Copy example file## ğŸ“‹ Prerequisites



- Use **Chrome/Edge** for best audio supportâ”œâ”€â”€ frontend/vite-project/  # React frontend

- Grant microphone permissions before starting

- Ensure stable internet for API callsâ”œâ”€â”€ ffmpeg-xxx-essentials_build/  # Download separately!copy .env.example .env

- Monitor ElevenLabs API usage limits

â””â”€â”€ README.md

## ğŸ”® Upcoming Features

```### 2. Download FFmpeg

- [ ] **Multi-language Support** - Support for 44+ languages

- [ ] **Interview Templates** - Pre-built question sets by technology

- [ ] **Advanced Analytics** - Performance scoring and insights

- [ ] **Video Integration** - Add video calling capabilities## ğŸ“œ License# Edit .env and add your API keys:```bash

- [ ] **Resume Parsing** - AI analysis of uploaded resumes

- [ ] **Admin Dashboard** - Interview management interface

- [ ] **Mobile App** - React Native companion app

MIT License - Free to use and modify!GEMINI_API_KEY=your_gemini_api_key_here# Windows: Download FFmpeg essentials

## ğŸ’° Cost Analysis



### Development Investment

- **Total Development Cost**: $36,320 (4.54 person-months)---ELEVENLABS_API_KEY=your_elevenlabs_api_key_here# Go to: https://www.gyan.dev/ffmpeg/builds/

- **Operational Cost**: $25-52/month (APIs + hosting)

- **Break-even**: ~1 user/month at $50 subscription



### Value Proposition**Built with â¤ï¸ using Flask, React, Gemini AI & ElevenLabs**ELEVENLABS_VOICE_ID=nPczCjzI2devNBz1zQrb# Download: "essentials" build (NOT full build)

- â±ï¸ **60% faster** than traditional interviews

- ğŸ’° **80% cheaper** than human interviewers```# Extract to project root folder

- ğŸ”„ **24/7 availability** for global access

- ğŸ“Š **Consistent evaluation** criteria



## ğŸ§ª Testing### 5. Get API Keys# Or use direct link:



```bash# https://www.gyan.dev/ffmpeg/builds/ffmpeg-release-essentials.zip

# Backend tests

cd backend**Gemini API (Required):**```

python -m pytest tests/

1. Go to [Google AI Studio](https://makersuite.google.com/app/apikey)

# Frontend tests

cd frontend/vite-project2. Create API key and add to `.env`### 3. Backend Setup

npm test



# Integration tests<<<<<<< HEAD

npm run test:e2e

```**ElevenLabs API (Required):**```bash- Python 3.8+

=======

## ğŸš€ Deployment**ElevenLabs API (Required):**.

1. Sign up at [ElevenLabs](https://elevenlabs.io/)```

### Development>>>>>>> 99d687f216995b82e7db2678c93f7ad5efabc3a8

```bash

# Backend1. Sign up at [ElevenLabs](https://elevenlabs.io/)

python app.py

2. Get API key from Profile â†’ API Keyscd backend- Node.js 16+

# Frontend

npm run dev3. Browse [Voice Library](https://elevenlabs.io/voice-library) for Voice IDs

```

pip install -r requirements.txt- FFmpeg (included in project)

### Production

```bash### 6. Run Backend

# Backend

pip install gunicorn```bash```- Gemini API Key

gunicorn -w 4 -b 0.0.0.0:5000 app:app

python app.py

# Frontend

npm run build```- ElevenLabs API Key

npm run preview

```Backend runs on `http://localhost:5000`



### Docker (Optional)### 3. Configure API Keys

```bash

docker-compose up --build### 7. Frontend Setup

```

```bash```bash## ğŸš€ Setup Instructions

## ğŸ¤ Contributing

cd frontend/vite-project

1. **Fork** the repository

2. **Create** a feature branch (`git checkout -b feature/amazing-feature`)npm install# Copy example file

3. **Commit** your changes (`git commit -m 'Add amazing feature'`)

4. **Push** to the branch (`git push origin feature/amazing-feature`)npm run dev

5. **Open** a Pull Request

```copy .env.example .env### Backend Setup

### Development Guidelines

- Follow existing code styleFrontend runs on `http://localhost:5173`

- Add tests for new features

- Update documentation

- Test with multiple browsers

## ğŸ¯ Usage

## ğŸ“„ License

# Edit .env and add your API keys:1. Navigate to backend directory:

This project is licensed under the **MIT License** - see the [LICENSE](LICENSE) file for details.

1. Open `http://localhost:5173`

## ğŸ‘¥ Support & Community

2. Click **"Start Interview"** GEMINI_API_KEY=your_gemini_api_key_here```powershell

- ğŸ› **Bug Reports**: [GitHub Issues](https://github.com/vandandalvi/AI_voiceChat/issues)

- ğŸ’¡ **Feature Requests**: [GitHub Discussions](https://github.com/vandandalvi/AI_voiceChat/discussions)3. Wait for AI greeting

- ğŸ“§ **Email**: vandandalvi@gmail.com

- ğŸŒŸ **Star this repo** if you find it helpful!4. Click **"Start Speaking"** to respondELEVENLABS_API_KEY=your_elevenlabs_api_key_herecd backend



## ğŸ™ Acknowledgments5. Click **"Stop Speaking"** when done



- **Google Gemini AI** - For intelligent conversation capabilities6. Continue the conversation!ELEVENLABS_VOICE_ID=nPczCjzI2devNBz1zQrb```

- **ElevenLabs** - For premium voice synthesis technology

- **OpenAI** - For inspiration from ChatGPT's conversational AI

- **React Team** - For the amazing frontend framework

- **Flask Community** - For the lightweight backend solution## ğŸ› ï¸ Tech Stack```



---



<div align="center">- **Backend:** Flask, Python 3.132. Create a virtual environment:



**â­ Star this repository if it helped you! â­**- **Frontend:** React 19, Vite



**Built with â¤ï¸ by [Vandan Dalvi](https://github.com/vandandalvi)**- **AI:** Google Gemini 2.0 Flash### 4. Get API Keys```powershell



*Making AI interviews accessible to everyone* ğŸš€- **TTS:** ElevenLabs Flash v2.5 



</div>- **STT:** Google Speech Recognitionpython -m venv venv

- **Audio:** FFmpeg (download required)

**Gemini API (Required):**```

## âš™ï¸ Configuration

1. Go to [Google AI Studio](https://makersuite.google.com/app/apikey)

### Voice Settings (in `app.py`)

```python2. Create API key and add to `.env`3. Activate virtual environment:

"voice_settings": {

    "stability": 0.3,        # Lower = more expressive  ```powershell

    "similarity_boost": 0.8, # Higher = closer to voice

    "style": 0.3,            # Style exaggeration**ElevenLabs API (Required):**.\venv\Scripts\Activate.ps1

    "use_speaker_boost": True # Enhanced clarity

}1. Sign up at [ElevenLabs](https://elevenlabs.io/)```

```

2. Get API key from Profile â†’ API Keys

### ElevenLabs Models (in `.env`)

- `eleven_flash_v2_5` - Fastest, lowest cost âœ…3. Browse [Voice Library](https://elevenlabs.io/voice-library) for Voice IDs4. Install dependencies:

- `eleven_turbo_v2_5` - High quality, fast

- `eleven_multilingual_v2` - 44 languages```powershell



## ğŸ”§ Troubleshooting### 5. Run Backendpip install -r requirements.txt



**FFmpeg Not Found:** Download from link above and extract to project root```bash```

**ElevenLabs 401 Error:** Set `USE_GTTS_FALLBACK=true` in `.env`

**No Microphone:** Grant browser permissionspython app.py

**CORS Errors:** Ensure Flask-CORS is installed

```5. Create `.env` file from `.env.example`:

## ğŸ“ Project Structure

Backend runs on `http://localhost:5000````powershell

```

AI_voiceChat/cp .env.example .env

â”œâ”€â”€ backend/

â”‚   â”œâ”€â”€ app.py              # Main Flask server### 6. Frontend Setup```

â”‚   â”œâ”€â”€ requirements.txt    # Dependencies

â”‚   â”œâ”€â”€ .env.example        # API keys template```bash

â”‚   â””â”€â”€ .env                # Your API keys (git ignored)

â”œâ”€â”€ frontend/vite-project/  # React frontendcd frontend/vite-project6. Edit `.env` and add your API keys:

â”œâ”€â”€ ffmpeg-xxx-essentials_build/  # Download separately!

â””â”€â”€ README.mdnpm install```

```

npm run devGEMINI_API_KEY=your_gemini_api_key_here

## ğŸ“œ License

```ELEVENLABS_API_KEY=your_elevenlabs_api_key_here

MIT License - Free to use and modify!

Frontend runs on `http://localhost:5173`ELEVENLABS_VOICE_ID=EXAVITQu4vr4xnSDxMaL

---

```

**Built with â¤ï¸ using Flask, React, Gemini AI & ElevenLabs**
## ğŸ¯ Usage

7. Run the Flask servereefefe

1. Open `http://localhost:5173````powershell

2. Click **"Start Interview"** python app.py

3. Wait for AI greeting```

4. Click **"Start Speaking"** to respond

5. Click **"Stop Speaking"** when doneThe backend will run on `http://localhost:5000`

6. Continue the conversation!

### Frontend Setup

## ğŸ› ï¸ Tech Stack

1. Navigate to frontend directory:

- **Backend:** Flask, Python 3.13```powershell

- **Frontend:** React 19, Vitecd frontend\vite-project

- **AI:** Google Gemini 2.0 Flash```

- **TTS:** ElevenLabs Flash v2.5 

- **STT:** Google Speech Recognition2. Install dependencies:

- **Audio:** FFmpeg (included)```powershell

npm install

## âš™ï¸ Configuration```



### Voice Settings (in `app.py`)3. Run the development server:

```python```powershell

"voice_settings": {npm run dev

    "stability": 0.3,        # Lower = more expressive  ```

    "similarity_boost": 0.8, # Higher = closer to voice

    "style": 0.3,            # Style exaggerationThe frontend will run on `http://localhost:5173`

    "use_speaker_boost": True # Enhanced clarity

}## ğŸ”‘ Getting API Keys

```

### Gemini API Key

### ElevenLabs Models (in `.env`)1. Go to [Google AI Studio](https://makersuite.google.com/app/apikey)

- `eleven_flash_v2_5` - Fastest, lowest cost âœ…2. Click "Get API Key"

- `eleven_turbo_v2_5` - High quality, fast3. Create a new project or select existing

- `eleven_multilingual_v2` - 44 languages4. Copy your API key



## ğŸ”§ Troubleshooting### ElevenLabs API Key

1. Go to [ElevenLabs](https://elevenlabs.io/)

**ElevenLabs 401 Error:** Set `USE_GTTS_FALLBACK=true` in `.env`2. Sign up for an account

**No Microphone:** Grant browser permissions3. Navigate to Profile Settings

**CORS Errors:** Ensure Flask-CORS is installed4. Copy your API key

5. (Optional) Go to Voice Library to get custom Voice IDs

## ğŸ“ Project Structure

## ğŸ¯ Usage

```

AI_voiceChat/1. Start both backend and frontend servers

â”œâ”€â”€ backend/2. Open browser to `http://localhost:5173`

â”‚   â”œâ”€â”€ app.py              # Main Flask server3. Click "Start Interview"

â”‚   â”œâ”€â”€ requirements.txt    # Dependencies4. Wait for the AI to speak the greeting

â”‚   â”œâ”€â”€ .env.example        # API keys template5. Click "Start Speaking" to respond

â”‚   â””â”€â”€ .env                # Your API keys (git ignored)6. Click "Stop Speaking" when done

â”œâ”€â”€ frontend/vite-project/  # React frontend7. Continue the conversation!

â”œâ”€â”€ ffmpeg-8.0-essentials_build/  # Audio processing

â””â”€â”€ README.md## ğŸ“ Project Structure

```

```

## ğŸ“œ LicensetalkitoP1/

â”œâ”€â”€ backend/

MIT License - Free to use and modify!â”‚   â”œâ”€â”€ app.py              # Flask server with API endpoints

â”‚   â”œâ”€â”€ requirements.txt    # Python dependencies

---â”‚   â”œâ”€â”€ .env.example        # Environment variables template

â”‚   â””â”€â”€ .gitignore         # Git ignore file

**Built with â¤ï¸ using Flask, React, Gemini AI & ElevenLabs**â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ vite-project/
â”‚       â”œâ”€â”€ src/
â”‚       â”‚   â”œâ”€â”€ App.jsx    # Main React component
â”‚       â”‚   â”œâ”€â”€ App.css    # Styles
â”‚       â”‚   â””â”€â”€ index.css  # Global styles
â”‚       â””â”€â”€ package.json   # Node dependencies
â””â”€â”€ ffmpeg-8.0-essentials_build/
    â””â”€â”€ bin/
        â””â”€â”€ ffmpeg.exe     # FFmpeg executable
```

## ğŸ”§ API Endpoints

### `POST /api/start-interview`
Start a new interview session and get greeting audio

### `POST /api/process-audio`
Process user audio: STT â†’ AI â†’ TTS
- Body: FormData with `audio` file

### `POST /api/text-to-speech`
Convert text to speech
- Body: `{ "text": "string" }`

### `GET /api/conversation-history`
Get conversation history

### `POST /api/reset`
Reset conversation

## âš ï¸ Important Notes

### Speech-to-Text Integration
The current implementation includes a **placeholder** for speech-to-text conversion. You need to integrate one of these services:

#### Option 1: OpenAI Whisper API (Recommended)
```python
import openai

def speech_to_text(audio_path):
    with open(audio_path, 'rb') as audio_file:
        transcript = openai.Audio.transcribe("whisper-1", audio_file)
        return transcript.text
```

#### Option 2: Google Cloud Speech-to-Text
```python
from google.cloud import speech

def speech_to_text(audio_path):
    client = speech.SpeechClient()
    with open(audio_path, 'rb') as audio_file:
        content = audio_file.read()
    audio = speech.RecognitionAudio(content=content)
    config = speech.RecognitionConfig(
        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
        sample_rate_hertz=16000,
        language_code="en-US",
    )
    response = client.recognize(config=config, audio=audio)
    return response.results[0].alternatives[0].transcript
```

#### Option 3: Azure Speech Services
```python
import azure.cognitiveservices.speech as speechsdk

def speech_to_text(audio_path):
    speech_config = speechsdk.SpeechConfig(
        subscription="YOUR_KEY", 
        region="YOUR_REGION"
    )
    audio_config = speechsdk.AudioConfig(filename=audio_path)
    speech_recognizer = speechsdk.SpeechRecognizer(
        speech_config=speech_config, 
        audio_config=audio_config
    )
    result = speech_recognizer.recognize_once()
    return result.text
```

## ğŸ› Troubleshooting

### Backend Issues
- **Port already in use**: Change port in `app.py`: `app.run(port=5001)`
- **API key errors**: Double-check your `.env` file
- **FFmpeg not found**: Verify FFmpeg path in `app.py`

### Frontend Issues
- **CORS errors**: Ensure Flask-CORS is installed and configured
- **Microphone access denied**: Grant browser microphone permissions
- **No audio playback**: Check browser audio permissions

### Audio Issues
- **Recording doesn't work**: Check browser compatibility (Chrome/Edge recommended)
- **Poor audio quality**: Adjust ElevenLabs voice settings in `app.py`

## ğŸ¨ Customization

### Change AI Interviewer Personality
Edit the context in `app.py` â†’ `get_gemini_response()`:
```python
context = """You are a [YOUR_PERSONALITY] interviewer..."""
```

### Change Voice
1. Get voice ID from [ElevenLabs Voice Library](https://elevenlabs.io/voice-library)
2. Update `ELEVENLABS_VOICE_ID` in `.env`

### Modify Interview Questions
Edit the greeting in `app.py` â†’ `start_interview()`:
```python
greeting = "Your custom greeting here"
```

## ğŸ“ License

MIT License

## ğŸ¤ Contributing

Pull requests are welcome! For major changes, please open an issue first.

## ğŸ“§ Support

For issues and questions, please open a GitHub issue.

---

Built with â¤ï¸ using React, Flask, Gemini AI, ElevenLabs, and FFmpeg
